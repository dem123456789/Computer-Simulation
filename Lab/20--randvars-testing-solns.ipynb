{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CX 4230, Spring 2016: [20] Generating Random Variates and Testing Random Number Generators\n",
    "\n",
    "## (Sample solutions)\n",
    "\n",
    "This notebook accompanies the slides presented in class: [link](https://t-square.gatech.edu/access/content/group/gtc-59b8-dc03-5a67-a5f4-88b8e4d5b69a/cx4230-sp16--20-rand-var-test.pdf).\n",
    "\n",
    "For a deeper survey of these ideas, see the readings from the last lab, especially volume 2 of Knuth's _The Art of Computer Programming_: [link](https://t-square.gatech.edu/access/content/group/gtc-59b8-dc03-5a67-a5f4-88b8e4d5b69a/Knuth-TAOCP-v2--9780133488791.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From uniform to arbitrary distributions\n",
    "\n",
    "Suppose you are given a way to generate a uniform random variable $U \\sim \\mathcal{U}(0, 1)$. How do you convert $U$ into a different random variable $X$ following some _other_ distribution, such as exponential?\n",
    "\n",
    "One technique is to \"invert\" the _cumulative distribution function_ (CDF) of $X$. Recall that the CDF of $X$ is a function\n",
    "\n",
    "$$\n",
    "  F_X(x) \\equiv \\mathrm{Pr}[X \\leq x].\n",
    "$$\n",
    "\n",
    "Given a sample value $u$ of the random variable $U$, you can convert $u$ into a sample $x$ of $X$ by\n",
    "\n",
    "$$\n",
    "  x = F_X^{-1}(u).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Let $X \\sim \\mathcal{E}(\\lambda)$ be an exponentially distributed random variable with mean $\\lambda$. Then it has a cumulative distribution\n",
    "\n",
    "$$\n",
    "  F_X(x) = 1 - e^{-x / \\lambda}.\n",
    "$$\n",
    "\n",
    "Given an observed sample $u$ of a random variable $U$, you would compute the sample $x$ by solving $u = F_X^{-1}(x)$ for $x$. The result would be\n",
    "\n",
    "$$\n",
    "  x = {-\\lambda \\ln (1-u)}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Implement a function to generate samples from $\\mathcal{E}(\\lambda)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random, seed\n",
    "from math import log\n",
    "\n",
    "def sample_exp (l):\n",
    "    \"\"\"Generates a sample from an exponential random variable with mean `l`.\"\"\"\n",
    "    # @YOUSE\n",
    "    u = random ()\n",
    "    x = -l * log (1-u)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean: 4.83646939019628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 104.,   66.,   37.,   20.,    8.,    7.,    4.,    2.,    1.,    1.]),\n",
       " array([  5.30790571e-03,   2.77581781e+00,   5.54632771e+00,\n",
       "          8.31683762e+00,   1.10873475e+01,   1.38578574e+01,\n",
       "          1.66283673e+01,   1.93988772e+01,   2.21693871e+01,\n",
       "          2.49398970e+01,   2.77104069e+01]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1041c6eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test code: Generate samples and plot them as a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 250\n",
    "l = 5.0\n",
    "seed (20160224)\n",
    "x = [sample_exp (l) for i in range (n)]\n",
    "\n",
    "x_mean = sum (x) / n\n",
    "print (\"Sample mean:\", x_mean)\n",
    "plt.hist (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating samples for an empirical CDF\n",
    "\n",
    "You can apply essentially the same idea to discrete random variables. Let's walk through an example.\n",
    "\n",
    "Suppose you wish to generate letters from a distribution that matches the empirically observed distribution of letters in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... downloading http://www.gutenberg.org/cache/epub/11/pg11.txt ...\n",
      "\n",
      "=== Snippet ===\n",
      "...  the cat.) 'I hope they'll remember her saucer of milk at\n",
      "tea-time. Dinah my dear! I wish you were down here with me! There are no\n",
      "mice in the air, I'm afraid, but you might catch a bat, and that's very\n",
      "like a mouse, you know. But do cats eat bats, I wonder?' And here Alice\n",
      "began to get rather sleepy, and went on saying to herself, in a dreamy\n",
      "sort of way, 'Do cats eat bats? Do cats eat bats?' and sometimes, 'Do\n",
      "bats eat cats?' for, you see, as she couldn't answer either question,\n",
      "it didn \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import requests # http://docs.python-requests.org/en/master/user/quickstart/#make-a-request\n",
    "\n",
    "def download_text (url):\n",
    "    print (\"... downloading\", url, \"...\")\n",
    "    req = requests.get (url)\n",
    "    return req.text\n",
    "\n",
    "text = download_text ('http://www.gutenberg.org/cache/epub/11/pg11.txt')\n",
    "#text = download_text ('http://www.gutenberg.org/cache/epub/15532/pg15532.txt')\n",
    "print (\"\\n=== Snippet ===\\n...\", text[5000:5500], \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** From what book was this text drawn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer: ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make a histogram of letter frequencies, stored as a dictionary where the key is the letter and the value is the number of occurrences of that letter. For simplicity, consider only alphabetic characters and normalize all characters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Occurrences: 122989 characters total ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'a': 9802,\n",
       "         'b': 1746,\n",
       "         'c': 3000,\n",
       "         'd': 5469,\n",
       "         'e': 15395,\n",
       "         'f': 2382,\n",
       "         'g': 2943,\n",
       "         'h': 7889,\n",
       "         'i': 8633,\n",
       "         'j': 235,\n",
       "         'k': 1290,\n",
       "         'l': 5211,\n",
       "         'm': 2467,\n",
       "         'n': 8051,\n",
       "         'o': 9477,\n",
       "         'p': 1968,\n",
       "         'q': 220,\n",
       "         'r': 6610,\n",
       "         's': 7268,\n",
       "         't': 12200,\n",
       "         'u': 3978,\n",
       "         'v': 963,\n",
       "         'w': 2952,\n",
       "         'x': 176,\n",
       "         'y': 2584,\n",
       "         'z': 80})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a histogram of individual characters. See: https://docs.python.org/2/library/collections.html\n",
    "from collections import Counter\n",
    "\n",
    "def count_chars (s):\n",
    "    \"\"\"\n",
    "    Given a string or list of characters `s`, this function returns a\n",
    "    histogram of the number of occurrences of alphabetic characters.\n",
    "    The histogram is stored as a dictionary and the characters are\n",
    "    normalized to lowercase.\n",
    "    \"\"\"\n",
    "    histogram = Counter ()\n",
    "    for c in s:\n",
    "        if c.isalpha ():\n",
    "            histogram[c.lower ()] += 1\n",
    "    return histogram\n",
    "\n",
    "# Count the occurrences of each (lowercase) alphabetic characters\n",
    "text_counts = count_chars (text)\n",
    "num_chars = sum (text_counts.values ())\n",
    "print (\"=== Occurrences:\", num_chars, \"characters total ===\")\n",
    "text_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this distribution a little easier to read, let's convert it to a list and sort by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 15395),\n",
       " ('t', 12200),\n",
       " ('a', 9802),\n",
       " ('o', 9477),\n",
       " ('i', 8633),\n",
       " ('n', 8051),\n",
       " ('h', 7889),\n",
       " ('s', 7268),\n",
       " ('r', 6610),\n",
       " ('d', 5469),\n",
       " ('l', 5211),\n",
       " ('u', 3978),\n",
       " ('c', 3000),\n",
       " ('w', 2952),\n",
       " ('g', 2943),\n",
       " ('y', 2584),\n",
       " ('m', 2467),\n",
       " ('f', 2382),\n",
       " ('p', 1968),\n",
       " ('b', 1746),\n",
       " ('k', 1290),\n",
       " ('v', 963),\n",
       " ('j', 235),\n",
       " ('q', 220),\n",
       " ('x', 176),\n",
       " ('z', 80)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function to \"sort\" dictionaries:\n",
    "# http://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n",
    "import operator\n",
    "\n",
    "def sort_dict (d, descending=False):\n",
    "    \"\"\"\n",
    "    Given a dictionary `d`, returns a list of (key, value) pairs sorted by value.\n",
    "    To sort in descending order, set `ascending=False`.\n",
    "    \"\"\"\n",
    "    if descending:\n",
    "        compare = lambda x: -(operator.itemgetter (1) (x))        \n",
    "    else:\n",
    "        compare = operator.itemgetter (1)\n",
    "    return sorted (d.items (), key=compare)\n",
    "\n",
    "text_counts_sorted = sort_dict (text_counts, descending=True)\n",
    "text_counts_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert these ordered counts into a CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Empirical CDF ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('e', 0.12517379603053932),\n",
       " ('t', 0.22436965907520184),\n",
       " ('a', 0.3040678434656758),\n",
       " ('o', 0.3811235151111075),\n",
       " ('i', 0.45131678442787565),\n",
       " ('n', 0.5167779232289067),\n",
       " ('h', 0.5809218710616396),\n",
       " ('s', 0.6400165868492305),\n",
       " ('r', 0.6937612306791664),\n",
       " ('d', 0.7382286220718927),\n",
       " ('l', 0.7805982648854776),\n",
       " ('u', 0.8129426208847945),\n",
       " ('c', 0.837335046223646),\n",
       " ('w', 0.8613371927570759),\n",
       " ('g', 0.8852661620144892),\n",
       " ('y', 0.9062761710396865),\n",
       " ('m', 0.9263348754766686),\n",
       " ('f', 0.9457024611957167),\n",
       " ('p', 0.9617038922180032),\n",
       " ('b', 0.9759002837652148),\n",
       " ('k', 0.9863890266609209),\n",
       " ('v', 0.9942189951946923),\n",
       " ('j', 0.9961297351795689),\n",
       " ('q', 0.9979185130377514),\n",
       " ('x', 0.9993495353242973),\n",
       " ('z', 1.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cumsum_key_value_pairs (p):\n",
    "    s = 0.0\n",
    "    p_cumulative = []\n",
    "    for (k, v) in p:\n",
    "        s = s + v\n",
    "        p_cumulative.append ((k, s))\n",
    "    return p_cumulative\n",
    "\n",
    "text_cdf = [(k, float (v)/num_chars) for (k, v) in cumsum_key_value_pairs (text_counts_sorted)]\n",
    "print (\"=== Empirical CDF ===\")\n",
    "text_cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Write a function to generate a sample from a discrete CDF like `text_cdf`. Recall that `text_cdf` is a list of (key, value) pairs where the key is an outcome of the random variable and the value is the cumulative probability of observing the key and all preceding keys in list order.\n",
    "\n",
    "> Hint: The [`bisect()`](https://docs.python.org/2/library/bisect.html) makes this task easy. In particular, given a list `X` of values in ascending order, `bisect(X, v)` returns the largest index `i` such `X[i] <= v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bisect import bisect # Per the hint\n",
    "\n",
    "def gen_sample (cdf):\n",
    "    \"\"\"\n",
    "    Given a discrete cumulative distribution function, this function returns\n",
    "    a single random sample from the distribution. The input CDF is given as\n",
    "    a list `cdf` of (`key`, `value`) pairs, where `value` is the cumulative\n",
    "    probability of observing the key and all preceding keys in the list.\n",
    "    \"\"\"\n",
    "    # @YOUSE\n",
    "    #return ...\n",
    "    u = random ()\n",
    "    i = bisect ([v for (_, v) in cdf], u)\n",
    "    return cdf[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 135),\n",
       " ('t', 110),\n",
       " ('h', 77),\n",
       " ('o', 74),\n",
       " ('s', 71),\n",
       " ('a', 69),\n",
       " ('i', 65),\n",
       " ('n', 61),\n",
       " ('l', 44),\n",
       " ('r', 44),\n",
       " ('d', 34),\n",
       " ('u', 27),\n",
       " ('c', 25),\n",
       " ('f', 23),\n",
       " ('g', 20),\n",
       " ('y', 20),\n",
       " ('w', 19),\n",
       " ('m', 18),\n",
       " ('p', 16),\n",
       " ('k', 15),\n",
       " ('b', 14),\n",
       " ('v', 11),\n",
       " ('j', 3),\n",
       " ('q', 2),\n",
       " ('x', 2),\n",
       " ('z', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code: Generate `n` samples and count the occurrences of each unique character.\n",
    "n = 1000\n",
    "sample = [gen_sample (text_cdf) for i in range (n)]\n",
    "sort_dict (count_chars (sample), descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square ($\\chi^2$) testing\n",
    "\n",
    "**Overview.** The previous example began with a \"true\" (empirical) distribution of letter frequencies, extracted from text real text. We then generated samples from this distribution.\n",
    "\n",
    "What if we had just been handed the generated samples. How could we check whether they came from our letter-frequency distribution? \n",
    "\n",
    "In class, we discussed one way to test how likely a random sample was to have been drawn from a given discrete distribution, using a method called the _chi-square ($\\chi^2$) test_. There are canned (black-box) routines to compute it, e.g., [`scipy.stats.chisquare()`](http://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.chisquare.html). Here is how we would apply it to the data for the pair of dice in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chisquare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c676374ea3c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_slides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_slides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mchisquare\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_slides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_exp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_slides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'chisquare' is not defined"
     ]
    }
   ],
   "source": [
    "# Check against slide data\n",
    "X_slides = [4, 8, 12, 16, 20, 24, 20, 16, 12, 8, 4]\n",
    "Y_slides = [2, 4, 10, 12, 22, 29, 21, 15, 14, 9, 6]\n",
    "chisquare (Y_slides, f_exp=X_slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for pedagogical purposes, let's see how it works the black-box actually works through a series of exercises. In these exercises, assume that the `sample` dictionary computed above is the set of values we are testing against a \"true\" distribution, which comes from the text (`text_counts`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Walk-through.** Per the class slides, consider a discrete distribution for which you know that any outcome $v$ occurs with probability $p_v$. You observe a random sample of size $n$, $\\{y_0, y_1, \\ldots, y_{n-1}\\}$. You wish to check how likely it is to have come from the given distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Convert the letter counts into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# @YOUSE: Compute a new dictionary of key-value pairs, (v, p_v), from `text_counts`.\n",
    "#text_probs = ...\n",
    "text_probs = {k: (float (v)/num_chars) for (k, v) in text_counts.items ()}\n",
    "text_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the _counts_ of the number of occurrences of $v$ in the sample. Denote these observed counts mathematically by $Y_v$.\n",
    "\n",
    "**Exercise.** Compute a dictionary `sample_counts[k] = c` where `k` is $v$ and `c` is $Y_v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# @YOUSE:\n",
    "#sample_counts = ...\n",
    "sample_counts = count_chars (sample)\n",
    "\n",
    "# Display\n",
    "sample_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the _chi-square statistic_, which is\n",
    "\n",
    "$$\n",
    "  \\chi^2 \\equiv \\sum_v \\dfrac{(Y_v - np_v)^2}{np_v},\n",
    "$$\n",
    "\n",
    "where $np_v$ is the expected number of occurrences of $v$ in a sample of size $n$.\n",
    "\n",
    "**Exercise.** Complete the following function, which computes the $\\chi^2$ statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_chisquare_statistic (counts, probs):\n",
    "    \"\"\"\n",
    "    Given a target distribution and empirically observed counts, compute the\n",
    "    chi-square statistic of the observations relative to the target.\n",
    "    \n",
    "    The input `counts[v] = y_v` is the dictionary of observations and\n",
    "    `probs[v] = p_v` is the probability of observing `v`.\n",
    "    \"\"\"\n",
    "    n = sum (counts.values ())\n",
    "    chi_sq = 0.0\n",
    "    # @YOUSE:\n",
    "    #assert False\n",
    "    for (v, y_v) in counts.items ():\n",
    "        x_v = float (n) * probs[v]\n",
    "        chi_sq += (y_v - x_v)**2 / x_v\n",
    "        if y_v < 5: print (\"*** Warning: Only\", y_v, \"< 5 samples of item\", v, \"***\")\n",
    "    return chi_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_chi2 = calc_chisquare_statistic (sample_counts, text_probs)\n",
    "print (\"\\nchi^2 for the random sample:\", sample_chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the $\\chi^2$ statistic, you also need to know the number of degrees of freedom of the distribution.\n",
    "\n",
    "**Exercise.** Compute the degrees of freedom of the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# @YOUSE\n",
    "#text_dof = ...\n",
    "text_dof = len (text_probs) - 1\n",
    "\n",
    "print (\"Degrees of freedom =\", text_dof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you would \"look up\" the chances of observing your $\\chi^2$ given the number of degrees of freedom. In Python, you can do this look-up by calling a function that evaluates the CDF of a $\\chi^2$ distribution. See: http://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.chi2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "chi2_stat_check = chi2.cdf (sample_chi2, text_dof)\n",
    "chi2_stat_check2 = 1 - chi2_stat_check\n",
    "print (\"chi^2 CDF:\", chi2_stat_check, \"/\", chi2_stat_check2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** What would you conclude about the likelihood that the random sample came from the target distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer: ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check.** Let's double-check your result against what the \"canned\" routine produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "def calc_chisquare (sample, probs):\n",
    "    assert (type (sample) is dict) or (type (sample) is Counter) # Counts\n",
    "    assert type (probs) is dict # Probabilities\n",
    "    \n",
    "    # Total number of samples\n",
    "    n_Y = sum (sample.values ())\n",
    "\n",
    "    Y = [] # Holds observed counts, $Y_v$ \n",
    "    X = [] # Holds expected counts, $X_v$\n",
    "\n",
    "    for (v, p_v) in probs.items (): # probabilities of the true distribution\n",
    "        x_v = p_v * n_Y\n",
    "        if v in sample:\n",
    "            y_v = sample[v]\n",
    "        else:\n",
    "            y_v = 0\n",
    "        X.append (x_v)\n",
    "        Y.append (y_v)\n",
    "    \n",
    "    return (chisquare (Y, f_exp=X), X, Y)\n",
    "\n",
    "chi2_result, _, _ = calc_chisquare (sample_counts, text_probs)\n",
    "print (chi2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra stuff: English vs. Spanish\n",
    "\n",
    "How does the frequency distribution of English differ from Spanish? Let's download an example of Spanish text, compute the letter frequencies, and compare that distribution against the one for the English text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Spanish contains a number of vowels that don't occur in English. To make this comparable, the [`unidecode` package](https://pypi.python.org/pypi/Unidecode) can normalize a general unicode string into its closest pure ASCII representation. However, since `unidecode` is not a part of most standard Python distributions, you might need to install it first (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Downloads and installs the unidecode module; see: https://pypi.python.org/pypi/Unidecode\n",
    "!pip install unidecode\n",
    "\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_es = download_text ('http://www.gutenberg.org/cache/epub/15532/pg15532.txt')\n",
    "# If you don't have unidecode, just comment this next line out:\n",
    "text_es = unidecode (text_es)\n",
    "print (\"\\n=== Snippet (Spanish text) ===\\n...\", text_es[5000:5500], \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_es_counts = count_chars (text_es)\n",
    "sort_dict (text_es_counts, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chars_es = sum (text_es_counts.values ())\n",
    "text_es_probs = {k: v/num_chars_es for (k, v) in text_es_counts.items ()}\n",
    "text_es_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_probs_sorted = sort_dict (text_probs, descending=True)\n",
    "x_labels = [k for (k, _) in text_probs_sorted]\n",
    "y_values = [v for (_, v) in text_probs_sorted]\n",
    "\n",
    "y_values_es = []\n",
    "for v in x_labels:\n",
    "    if v in text_es_probs:\n",
    "        y_v = text_es_probs[v]\n",
    "    else:\n",
    "        y_v = 0.0\n",
    "    y_values_es.append (y_v)\n",
    "\n",
    "x_values = range (len (x_labels))\n",
    "w = 0.25\n",
    "fig = plt.figure (figsize=(16, 6))\n",
    "ax = fig.add_subplot (111)\n",
    "ax.bar ([x-w for x in x_values], y_values, w, color='b')\n",
    "ax.bar (x_values, y_values_es, w, color='r')\n",
    "ax.set_xticks (x_values)\n",
    "ax.set_xticklabels (x_labels)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_chisquare (text_es_counts, text_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
