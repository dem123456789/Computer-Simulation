{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CX 4230, Spring 2016: [23] Output analysis\n",
    "\n",
    "You've modeled inputs, built a simulator, and now the simulator is running correctly and producing outputs. Now what?\n",
    "\n",
    "This notebook accompanies the slides from the Wednesday, March 2 class: [link to T-Square](https://t-square.gatech.edu/access/content/group/gtc-59b8-dc03-5a67-a5f4-88b8e4d5b69a/cx4230-sp16--23-output-analysis.pdf)\n",
    "\n",
    "Some handy resources for today's notebook:\n",
    "* Numpy's random number generators: http://docs.scipy.org/doc/numpy/reference/routines.random.html\n",
    "* Making histograms: http://matplotlib.org/1.2.1/examples/pylab_examples/histogram_demo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "np.set_printoptions (linewidth=100, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "Let's start by checking the Central Limit Theorem (CLT) experimentally.\n",
    "\n",
    "Suppose we have built a simulator that produces a single output value each time it runs. By the argument from class, suppose we may assume that the output of each run $i$ is a random variable $Y_i$, where all $\\{Y_i\\}$ random variables are independent and identically distributed with some true underlying mean $\\mu$ and variance $\\sigma^2$.\n",
    "\n",
    "Here is a hypothetical simulator that obeys these assumptions, at least approximately. In particular, it simply draws output values from an exponential distribution with mean $\\mu$, i.e., $Y_i \\sim \\mathcal{E}(\\mu)$. As it happens, the variance of such a distribution is $\\sigma^2 = \\mu^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MU_TRUE = 1.0\n",
    "\n",
    "def fake_simulator (mu=MU_TRUE):\n",
    "    \"\"\"\n",
    "    Pretends to simulate some process that produces\n",
    "    a single output value.\n",
    "    \"\"\"\n",
    "    return np.random.exponential (mu)\n",
    "\n",
    "VAR_TRUE = MU_TRUE * MU_TRUE\n",
    "\n",
    "# Demo\n",
    "fake_simulator ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of these $n$ runs is another random variable, $\\bar{Y}$, where\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\bar{Y} & \\equiv & \\dfrac{1}{n} \\sum_{i=0}^{n-1} Y_i.\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "The _Central Limit Theorem_ tells us that the mean will be distributed normally (i.e., as a Gaussian) with mean and variance given by\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\bar{Y} & \\sim & \\mathcal{N}\\left(\\mu, \\dfrac{\\sigma^2}{\\sqrt{n}}\\right)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "as the number of samples $n \\rightarrow \\infty$. In other words, the mean of $n$ runs will tend toward the true mean with less and less uncertainty as $n$ increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Complete the following function, which conducts a given number of \"experiments,\" where each experiment is a single run of a given simulator. It returns an array containing the outputs of all these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_experiments (simulator, num_experiments):\n",
    "    \"\"\"\n",
    "    This function repeatedly calls a simulator and records the outputs.\n",
    "    The simulator must be a function, `simulator()`, that returns a\n",
    "    single floating-point output value. This function will call the\n",
    "    simulator `num_experiments` times and return all outputs.\n",
    "    \"\"\"\n",
    "    assert hasattr(simulator, '__call__') # `simulator` must be a function\n",
    "    Y = np.zeros (num_experiments)\n",
    "    \n",
    "    # @YOUSE: Run simulator and record outputs in Y[:]\n",
    "    assert False\n",
    "        \n",
    "    return Y\n",
    "\n",
    "# Demo\n",
    "n_e = 10\n",
    "Y = do_experiments (fake_simulator, n_e)\n",
    "print (\"n_e =\", n_e, \"==>\", np.mean (Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Complete the following function, which runs batches of experiments. Each batch consists of running the simulator a given number of times; the number of batches is also given. For each batch, it should record the mean of the simulator runs. It should then return all of those means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeat_experiments (simulator, num_experiments, num_batches):\n",
    "    \"\"\"\n",
    "    This function repeats a batch of simulation experiments many times,\n",
    "    return the means of each batch.\n",
    "    \n",
    "    It uses `do_experiments()` to run one batch of experiments, and\n",
    "    repeats batch runs `num_batches` times.\n",
    "    \"\"\"\n",
    "    Y_bar = np.zeros (num_batches) # Stores the means of each batch\n",
    "    \n",
    "    # @YOUSE: Run batches and record means\n",
    "    assert False\n",
    "        \n",
    "    return Y_bar\n",
    "\n",
    "# Demo\n",
    "n_b = 10 # Number of batches\n",
    "for n_e in [10, 100, 1000]:\n",
    "    print (n_e, \"=>\", repeat_experiments (fake_simulator, n_e, n_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Another demo, which plots the means of all batches for varying\n",
    "# numbers of experimental trials per batch.\n",
    "\n",
    "fig = plt.figure (figsize=(16, 6))\n",
    "ax = fig.add_subplot (111)\n",
    "\n",
    "n_b = 100 # Number of batches\n",
    "for n_e in [10, 100, 1000]:\n",
    "    x = np.arange (n_b)\n",
    "    y = repeat_experiments (fake_simulator, n_e, n_b)\n",
    "    ax.plot (x, y, label=str (n_e))\n",
    "    \n",
    "ax.legend ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Run the following interactive demo to verify the behavior of the CLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viz_exp (num_experiments=100, num_repetitions=100):\n",
    "    \"\"\"\n",
    "    Runs many batches of \"fake\" experiments. Plots a\n",
    "    histogram and adds a best-fit Gaussian to the plot.\n",
    "    \"\"\"\n",
    "    Y_bar = repeat_experiments (fake_simulator,\n",
    "                                num_experiments,\n",
    "                                num_repetitions)\n",
    "    \n",
    "    fig = plt.figure (figsize=(12, 6))\n",
    "    ax = fig.add_subplot (111)\n",
    "    H, Bins, _ = ax.hist (Y_bar, normed=1)\n",
    "    plt.xlim ([0.5, 1.5])\n",
    "    plt.ylim ([0, 20])\n",
    "    \n",
    "    # Add best-fit Gaussian\n",
    "    X_fit = np.linspace (0.5, 1.5)\n",
    "    Y_fit = mlab.normpdf (X_fit, MU_TRUE, VAR_TRUE/sqrt (num_experiments))\n",
    "    plt.plot (X_fit, Y_fit, 'r--', linewidth=4)\n",
    "    \n",
    "# Demo\n",
    "x = interact (viz_exp\n",
    "              , num_experiments=(100, 2000, 100)\n",
    "              , num_repetitions=(10, 100, 10)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $t$-test\n",
    "\n",
    "Suppose you run the simulation $n$ times, observing the output values $y_0$, $y_1$, $\\ldots$, $y_{n-1}$. From these observations you then compute the _sample mean_,\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\bar{y} & \\leftarrow & \\dfrac{1}{n} \\sum_{i=0}^{n-1} y_i.\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Since you only have one realization of experiments (i.e., one set of observations), this sample mean is a _point estimate_. How close is this point estimate to the true mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following test statistic, which is sometimes also referred to as the _$t$-statistic_, denoted $t_n$. It is defined in terms of the sample mean ($\\bar{y}$) and the _sample variance_, $s_n^2$.\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  s_n^2 & \\leftarrow & \\dfrac{1}{n} \\sum_{i=0}^{n-1} (y_i - \\bar{y})^2 \\\\\n",
    "  t_n & \\equiv & \\dfrac{\\bar{y} - \\mu}{s_n / \\sqrt{n-1}}.\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $t_n$ is not actually computable in general, as it depends on the _true_ mean, which you don't know. Nevertheless, and quite remarkably, the _distribution_ of $t_n$ _is_ known! In particular, $t_n$ follows [_Student's $t$-distribution_](http://mathworld.wolfram.com/Studentst-Distribution.html), which is parameterized by $n$.\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  t_n & \\sim & \\mathrm{Student}(n-1).\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Moreover, the cumulative distribution function (CDF) of a Student-$t$ random variable is known. Let's call the CDF $F_n(x) \\equiv \\mathrm{Pr}[t_n \\leq x]$. Then, it is possible to compute the probability that $t_n$ falls within some range.\n",
    "\n",
    "For example, suppose we wish to know the probability that $t_n$ falls between $-x$ and $x$. In terms of the CDF,\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\mathrm{Pr}[-x \\leq t_n \\leq x] & = & F_n(x) - F_n(-x).\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "As it happens, $F_n(x)$ is also symmetric about 0. Therefore, $F_n(x) = 1 - F_n(-x)$ and\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\mathrm{Pr}[-x \\leq t_n \\leq x] & = & 2 F_n(x) - 1.\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $t_n$ depends on the true mean, $\\mu$, which is unknown. But since the relationship between $t_n$ and $\\mu$ _is_ known, you can try to rewrite the probability that $t_n$ falls within some range into an equivalent statement about $\\mu$. You would then find,\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\mathrm{Pr}[-x \\leq t_n \\leq x]\n",
    "    & = & \\mathrm{Pr}\\left[-x \\leq \\dfrac{\\bar{y} - \\mu}{s_n / \\sqrt{n-1}} \\leq x\\right] \\\\\n",
    "    & = & \\mathrm{Pr}\\left[\\bar{y} - \\dfrac{s_n}{\\sqrt{n-1}} x \\leq \\mu \\leq \\bar{y} + \\dfrac{s_n}{\\sqrt{n-1}}x \\right]\n",
    "    & = & 2 F_n(x) - 1.\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "In other words, the true mean, $\\mu$, falls within $\\pm \\dfrac{x s_n}{\\sqrt{n-1}}$ of $\\bar{y}$ with some probability that can be computed from the CDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now flip this fact around! That is, you can compute how large a window around $\\bar{y}$ you would need to ensure that the probability of the true mean falling in that window is, say, $1 - \\alpha$, where you choose $\\alpha$ based on your personal tolerance for uncertainty. (A typical value is $\\alpha=0.1$.) Then,\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  2 F_n(x) - 1 & = & 1 - \\alpha \\\\\n",
    "  x & = & F_n^{-1}\\left(1 - \\dfrac{\\alpha}{2}\\right).\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "The interval $\\bar{y} \\pm \\dfrac{F_n^{-1}\\left(1 - \\dfrac{\\alpha}{2}\\right) s_n}{\\sqrt{n-1}}$ is known as the _$(1 - \\alpha)$ confidence interval_. For instance, choosing $\\alpha=0.1$ yields a 90% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Try running 10 simulations and compute the sample mean. Then compute a 95% confidence interval around this sample mean.\n",
    "\n",
    "> Use the `ppf()` function available in Scipy to invert the CDF: http://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.stats.t.html\n",
    ">\n",
    "> The example below computes $F_9^{-1}(0.95)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of the inverse CDF\n",
    "\n",
    "from scipy.stats import t\n",
    "\n",
    "t.ppf (0.95, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_e = 10\n",
    "Y = do_experiments (fake_simulator, n_e)\n",
    "y_bar = np.mean (Y)\n",
    "s_n = np.std (Y)\n",
    "\n",
    "# @YOUSE: Compute a 1-alpha confidence interval, y +/- dy\n",
    "alpha = 0.05\n",
    "dy = ...\n",
    "assert False\n",
    "\n",
    "# Test code\n",
    "if MU_TRUE < (y_bar-dy) or MU_TRUE > (y_bar + dy):\n",
    "    err_flag = '**'\n",
    "else:\n",
    "    err_flag = ''\n",
    "print (n_e, \"=>\", y_bar, \"+/-\", dy, err_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** How many runs (`n_e` above) are needed to get a 95% confidence interval of size +/- 10%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
